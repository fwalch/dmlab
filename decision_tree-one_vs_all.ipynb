{
 "metadata": {
  "name": "",
  "signature": "sha256:3cbeeede66d1b295d82bb2f8db0cc11eef2ea4d449baaba57fa486ab809a6ff7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "One-vs-all decision trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import os\n",
      "from parser import Parser as P\n",
      "import numpy as np\n",
      "\n",
      "with open(os.path.join(P.data_dir(), 'preprocessed.json')) as infile:\n",
      "    data = json.load(infile)\n",
      "    neutral_landmarks = np.array(data['neutral_landmarks'])\n",
      "    peak_landmarks = np.array(data['peak_landmarks'])\n",
      "    emotions = np.array(data['emotions'])\n",
      "    del data\n",
      "\n",
      "assert len(neutral_landmarks) == len(peak_landmarks)\n",
      "assert len(neutral_landmarks) == len(emotions)\n",
      "N = len(emotions)\n",
      "print('Number of image sequences: {0}'.format(N))\n",
      "number_of_landmarks = neutral_landmarks.shape[1]\n",
      "assert number_of_landmarks == 68"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of image sequences: 593\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Normalization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Normalize for each face individually\n",
      "from sklearn import preprocessing\n",
      "\n",
      "for image_sequence_number in range(N):\n",
      "    neutral_landmarks[image_sequence_number, :, :] = preprocessing.scale(neutral_landmarks[image_sequence_number, :, :])\n",
      "    peak_landmarks[image_sequence_number, :, :] = preprocessing.scale(peak_landmarks[image_sequence_number, :, :])\n",
      "    #neutral_landmarks[image_sequence_number, :, :] =\n",
      "    #    neutral_landmarks[image_sequence_number, :, :]-neutral_landmarks[image_sequence_number, :, :].mean(axis=0)\n",
      "    #peak_landmarks[image_sequence_number, :, :] =\n",
      "    #    peak_landmarks[image_sequence_number, :, :]-peak_landmarks[image_sequence_number, :, :].mean(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature exctraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract component-wise distances as features\n",
      "feature_names = ['distance (x)', 'distance (y)']\n",
      "distances = peak_landmarks-neutral_landmarks\n",
      "\n",
      "number_of_features = len(feature_names)\n",
      "\n",
      "assert distances.shape[2] == number_of_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "For each emotion, create one-vs-all decision tree"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "from sklearn import tree\n",
      "from sklearn.externals.six import StringIO\n",
      "import os\n",
      "import matplotlib.pyplot as plt\n",
      "import itertools as it\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
      "\n",
      "# Decision tree for one-vs-all emotions\n",
      "for emotion in set(emotions):\n",
      "    # Don't try to predict images with an unknown emotion\n",
      "    if emotion == None:\n",
      "        continue\n",
      "\n",
      "    emotion_name = P.emotion_to_str(emotion)\n",
      "\n",
      "    y = np.zeros(emotions.shape, dtype='int')\n",
      "    y[emotions == emotion] = 1\n",
      "    y[emotions != emotion] = -1\n",
      "    \n",
      "    X = distances.reshape((-1, number_of_landmarks*len(feature_names)))\n",
      "    clf = tree.DecisionTreeClassifier()\n",
      "    clf = clf.fit(X, y)\n",
      "\n",
      "    with open(os.path.join(P.data_dir(), \"{0}-vs-all.dot\".format(emotion_name)), 'w') as f:\n",
      "        features = list('LM {0}, {1}'.format(x, y) for x, y in it.product(range(number_of_landmarks), feature_names))\n",
      "        f = tree.export_graphviz(clf, out_file=f, feature_names=features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}