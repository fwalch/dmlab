{
 "metadata": {
  "name": "",
  "signature": "sha256:d07f011e60164fde981e30d59f0c0bcf44dd2e109a7444bfac77fe408300e7cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "One-vs-all"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import os\n",
      "from parser import Parser as P\n",
      "import numpy as np\n",
      "\n",
      "with open(os.path.join(P.data_dir(), 'preprocessed.json')) as infile:\n",
      "    data = json.load(infile)\n",
      "    neutral_landmarks = np.array(data['neutral_landmarks'])\n",
      "    peak_landmarks = np.array(data['peak_landmarks'])\n",
      "    emotions = np.array(data['emotions'])\n",
      "    del data\n",
      "\n",
      "assert len(neutral_landmarks) == len(peak_landmarks)\n",
      "assert len(neutral_landmarks) == len(emotions)\n",
      "N = len(emotions)\n",
      "print('Number of image sequences: {0}'.format(N))\n",
      "number_of_landmarks = neutral_landmarks.shape[1]\n",
      "assert number_of_landmarks == 68"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Normalization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Normalize for each face individually\n",
      "from sklearn import preprocessing\n",
      "\n",
      "for image_sequence_number in range(N):\n",
      "    neutral_landmarks[image_sequence_number, :, :] = preprocessing.scale(neutral_landmarks[image_sequence_number, :, :])\n",
      "    peak_landmarks[image_sequence_number, :, :] = preprocessing.scale(peak_landmarks[image_sequence_number, :, :])\n",
      "    #neutral_landmarks[image_sequence_number, :, :] =\n",
      "    #    neutral_landmarks[image_sequence_number, :, :]-neutral_landmarks[image_sequence_number, :, :].mean(axis=0)\n",
      "    #peak_landmarks[image_sequence_number, :, :] =\n",
      "    #    peak_landmarks[image_sequence_number, :, :]-peak_landmarks[image_sequence_number, :, :].mean(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature exctraction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract component-wise distances as features\n",
      "feature_names = ['distance (x)', 'distance (y)']\n",
      "distances = peak_landmarks-neutral_landmarks\n",
      "\n",
      "# Use euclidean distance\n",
      "#feature_names = ['euclidean distance']\n",
      "#distances = np.linalg.norm(peak_landmarks-neutral_landmarks, axis=2)\n",
      "\n",
      "number_of_features = len(feature_names)\n",
      "if number_of_features > 1:\n",
      "    assert distances.shape[2] == number_of_features\n",
      "else:\n",
      "    assert len(distances.shape) == 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "For each emotion, get most distinctive landmark"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "from sklearn import preprocessing\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn import metrics\n",
      "from sklearn import tree\n",
      "from sklearn.externals.six import StringIO\n",
      "import os\n",
      "import matplotlib.pyplot as plt\n",
      "import itertools as it\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
      "\n",
      "for emotion in set(emotions):\n",
      "    # Don't try to predict images with an unknown emotion\n",
      "    if emotion == None:\n",
      "        continue\n",
      "\n",
      "    emotion_name = P.emotion_to_str(emotion)\n",
      "\n",
      "    y = np.zeros(emotions.shape, dtype='int')\n",
      "    y[emotions == emotion] = 1\n",
      "    y[emotions != emotion] = -1\n",
      "\n",
      "    def get_color(e):\n",
      "        if e == emotion:\n",
      "            return 'g'\n",
      "        return 'r'\n",
      "\n",
      "    landmark_scores = []\n",
      "    for landmark_number in range(distances.shape[1]):\n",
      "        X = preprocessing.scale(distances[:, landmark_number]).reshape((-1, number_of_features)) # normalize accross landmarks\n",
      "        assert len(X) == N\n",
      "\n",
      "        km = KMeans(n_clusters=2)\n",
      "        km.fit(X)\n",
      "\n",
      "        rand_score = metrics.adjusted_rand_score(y, km.labels_)\n",
      "        landmark_scores.append((rand_score, landmark_number, X, km.cluster_centers_))\n",
      "\n",
      "    best_landmark = max(landmark_scores, key=lambda x: x[0])\n",
      "\n",
      "    if True and number_of_features > 1: #Plot?\n",
      "        X = best_landmark[2]\n",
      "        C = best_landmark[3]\n",
      "        landmark_number = best_landmark[1]\n",
      "        rand_score = best_landmark[0]\n",
      "        plt.clf()\n",
      "        colors = [get_color(emotion) for emotion in emotions]\n",
      "        plt.scatter(X[:, 0], X[:, 1], marker='o', alpha=0.8, s=20, linewidths=0, color=colors)\n",
      "        plt.scatter(C[:, 0], C[:, 1], marker='x', s=169, linewidths=3, color='b', zorder=10)\n",
      "        plt.title(\"{0}, LM {1}; rand score: {2:0.3f}\".format(emotion_name, landmark_number, rand_score))\n",
      "        plt.xlabel(feature_names[0])\n",
      "        plt.ylabel(feature_names[1])\n",
      "\n",
      "        plt.show()\n",
      "        \n",
      "    print('Best landmark for {emotion}: {landmark_number} (score: {score})'.format(emotion=emotion_name,\n",
      "                                                                                   landmark_number=best_landmark[1],\n",
      "                                                                                   score=best_landmark[0]))\n",
      "    if False: # print full scores?\n",
      "        print('Full scores for {emotion}:'.format(emotion=emotion_name))\n",
      "        for landmark in sorted(landmark_scores, key=lambda x: x[0], reverse=True):\n",
      "            print('\\t{score}: LM {landmark_number}'.format(landmark_number=landmark[1],\n",
      "                                                           score=landmark[0]))\n",
      "\n",
      "    X = distances.reshape((-1, number_of_landmarks*len(feature_names)))\n",
      "    clf = tree.DecisionTreeClassifier()\n",
      "    clf = clf.fit(X, y)\n",
      "\n",
      "    with open(os.path.join(P.data_dir(), \"{0}.dot\".format(emotion_name)), 'w') as f:\n",
      "        features = list('LM {0}, {1}'.format(x, y) for x, y in it.product(range(number_of_landmarks), feature_names))\n",
      "        f = tree.export_graphviz(clf, out_file=f, feature_names=features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}